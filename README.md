# Mixed XGboost and Genetic Algorithm

This repo contains tutorials covering reinforcement learning using scikit-learn 0.23.2 and xgboost 1.2.1 using Python 3.6.8


## Getting Started

To install Gym, see installation instructions on the [Gym GitHub repo](https://github.com/openai/gym).

## Tutorials

Step1: Convert the training data in CSV file format into pickle format (the data is divided into four parts: feature data, real tags, ignorable tags (the current diagnosis does not have a tag, but it has one with 100 days of diagnosis), data source (PID, time))
Step2: According to the data generated by step1, the labels are processed as follows: label the data as one if the actual label exists, 0 if the actual label does not exist and is not in the list of ignorable labels. Other cases are excluded from the group. This labeling process results in multiple single-label training data. Based on the training data, we trained an xgboost model to get the optimal single-label training model; the default cutoff value of each model is set to 0.5.
Step3: According to the model generated by step2, make a prediction for each data in the validation set and get the multi-label score vector corresponding to each sample.
Step4(ga_op): Apply the cutoff value under multi-label as the input variable, and combine the multi-label scores in the validation set in Step3. Use mAP as the evaluation function, and use GA algorithm for parameter optimization to obtain the optimal cutoff value vector.


Additional file descriptions.
report_gen: generate a report based on a score file and a set of thresholds (if not, it is the default 0.5)
param_gen: generate the feature weights for each label according to the model file
weight_pic_gen: generate the feature display for each label according to the model file



## References
......